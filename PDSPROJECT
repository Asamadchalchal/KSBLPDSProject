echo "# KSBLPDSProject" >> README.md
git init
git add README.md
git commit -m "first commit"
git branch -M main
git remote add origin https://github.com/Asamadchalchal/KSBLPDSProject.git
git push -u origin main
"""
"""
Created on Sun Apr  30 21:58:56 2023

@author: ateebmuh
"""


import pandas as pd
import numpy as np
import datetime as dt

"""---import all data sets---"""

# Dataset which contains information of customer and their location
# customer_info = pd.read_csv('olist_customers_dataset.csv')

# Dataset which contains information of Brazilian zip codes and its lat/lng
# coordinates
# location_info = pd.read_csv('olist_geolocation_dataset.csv')

# Dataset which contains data of items purchased within each order.
# order_items = pd.read_csv('olist_order_items_dataset.csv')

# Dataset that includes data about the orders payment options.
# mode_of_payments = pd.read_csv('olist_order_payments_dataset.csv')

# Dataset which includes data about the reviews of customers.
# customer_reviews = pd.read_csv('olist_order_reviews_dataset.csv')

# Main dataset
# orders_info = pd.read_csv('olist_orders_dataset.csv')

# Dataset which includes data about the products sold by Olist.
# product_sold = pd.read_csv('olist_products_dataset.csv')

# Dataset contains data about sellers that fulfilled orders made at Olist.
# sellers = pd.read_csv('olist_sellers_dataset.csv')

# Translates the product_category_name to english.
# translation = pd.read_csv('product_category_name_translation.csv')




"""---dealing with null values---"""



"""---customer_info---"""
# print(customer_info.isna().sum())
# no null values found

"""---location_info---"""
# print(location_info.isna().sum())
# no null valuesfound

"""---order_items---"""
# print(order_items.isna().sum())
# no null values found

"""---mode_of_payments---"""
# print(mode_of_payments.isna().sum())
# no null values found

"""---customer_reviews---"""
# print(customer_reviews.isna().sum())
# Two null values found in columns 
# 'review_comment_title'; 'review_comment_message'

# dropping null values columns because we only need review scores 
# not the commments, comments are also in brazilian language

# print(reviews_data.head())

# customer_reviews = customer_reviews.drop
# (["review_comment_title","review_comment_message"], axis='columns')

# print(customer_reviews.head())

# print(customer_reviews.isna().sum())
# two irrelevant columns with null values were removed

"""---orders_info---"""
# print(orders_info.isna().sum())
# Null values found in three columns date, time columns

# We shall drop rows with null values it is immaterial i.e. 2.98%
# print(orders_info.shape)

# orders_info.dropna(inplace=True)
# print(orders_info.shape)

# removing null values
# print(orders_info.isna().sum())   


"""---product_sold---"""
# print(product_sold.isna().sum())    
# null values in product_category_name, product_name_length,
# product_description_length, product_photos_qty, weight, length, height

# replacing null values with "Name not avaiable" in product_category_name

# product_sold['product_category_name'] = 
# product_sold['product_category_name'].fillna('Name not avaiable')


# Numerical columns null values replaced by correspoding columns mean

# x = product_sold["product_name_length"].mean()
# product_sold["product_name_length"].fillna(x, inplace = True)

# y = product_sold["product_description_length"].mean()
# product_sold["product_description_length"].fillna(y, inplace = True)

# z = product_sold["product_photos_qty"].mean()
# product_sold["product_photos_qty"].fillna(z, inplace = True)


# for columns weight, lenth and height null values will be dropped

# product_sold.dropna(inplace=True)

# print(product_sold.isna().sum())  

# null values dealt with


"""---sellers---"""
# print(sellers.isna().sum())    
# no null values found

"""---translation---"""

# print(translation.isna().sum())     
# no null values found

# null values dealt with, in all data frames


"""---dealing with duplicate values---"""


"""---customer_info---"""
# print(customer_info.duplicated().sum()) 
# no duplicates found

"""---location_info---"""
# print(location_info.duplicated().sum())       
# duplicates found

# location_info.drop_duplicates(inplace = True)
# print(location_info.duplicated().sum())    
# duplicates removed


"""---order_items---"""
# print(order_items.duplicated().sum())   
# no duplicates found

"""---mode_of_payments---"""
# print(mode_of_payments.duplicated().sum())
# no duplicates found

"""---customer_reviews---"""
# print(customer_reviews.duplicated().sum())
# no duplicates found

"""---orders_info---"""
# print(orders_info.duplicated().sum())
# no duplicates found

"""---product_sold---"""
# print(product_sold.duplicated().sum())
# no duplicates found

"""---sellers---"""
# print(sellers.duplicated().sum())
# no duplicates found

"""---translation---"""
# print(translation.duplicated().sum())       # no duplicates found

# duplicates dealt with, in all data frames




"""---standardization---"""

"""---standardizing all dates and converting them to datetime objects---"""


# customer_reviews['review_answer_timestamp'] = pd.to_datetime(customer_reviews['review_answer_timestamp'])
# order_items['shipping_limit_date'] = pd.to_datetime(order_items['shipping_limit_date'])
# orders_info['order_purchase_timestamp'] = pd.to_datetime(orders_info['order_purchase_timestamp'])
# orders_info['order_approved_at'] = pd.to_datetime(orders_info['order_approved_at'])
# orders_info['order_delivered_carrier_date'] = pd.to_datetime(orders_info['order_delivered_carrier_date'])
# orders_info['order_delivered_customer_date'] = pd.to_datetime(orders_info['order_delivered_customer_date'])
# orders_info['order_estimated_delivery_date'] = pd.to_datetime(orders_info['order_estimated_delivery_date'])

# dates standardized in all data frames
